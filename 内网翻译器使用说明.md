# 内网翻译器使用说明

## 概述

内网翻译器是新增的第四个翻译平台，支持使用内网部署的OpenAI兼容API进行翻译。该功能已完全集成到现有系统中，与其他翻译器（智谱AI、Ollama、硅基流动）具有相同的功能和接口。

## 功能特性

- **OpenAI兼容API**: 支持标准的OpenAI Chat Completions API格式
- **灵活配置**: 可自定义API地址、模型名称和超时时间
- **按需检测**: 仅在用户选择时进行连接检测，不影响系统启动速度
- **模型管理**: 支持多种常见的内网部署模型
- **术语支持**: 完全支持术语库和术语预处理功能
- **Web界面集成**: 在Web界面中可以选择和切换到内网翻译器
- **状态监控**: 提供专门的状态检查接口

## 配置说明

### 配置文件位置
内网翻译器的配置位于 `config.json` 文件中的 `intranet_translator` 部分：

```json
{
    "intranet_translator": {
        "type": "intranet",
        "api_url": "http://192.168.100.71:8000/v1/chat/completions",
        "model": "deepseek-r1-70b",
        "timeout": 60.0
    }
}
```

### 配置参数说明

- **api_url**: 内网API的完整地址
  - 格式: `http://IP地址:端口/v1/chat/completions`
  - 示例: `http://192.168.100.71:8000/v1/chat/completions`

- **model**: 使用的模型名称
  - 默认: `deepseek-r1-70b`
  - 支持的模型见下方列表

- **timeout**: 请求超时时间（秒）
  - 默认: 60.0
  - 建议范围: 30-120秒

## 支持的模型

内网翻译器预配置了以下常见模型：

1. **DeepSeek系列**
   - `deepseek-r1-70b` (默认)
   - `deepseek-r1-32b`
   - `deepseek-r1-8b`

2. **Qwen系列**
   - `qwen2.5-72b`
   - `qwen2.5-32b`
   - `qwen2.5-14b`
   - `qwen2.5-7b`

3. **LLaMA系列**
   - `llama3.1-70b`
   - `llama3.1-8b`

*注意: 实际可用的模型取决于您的内网部署情况*

## 使用方法

### 1. Web界面使用

1. 启动Web服务器：
   ```bash
   python web_server.py
   ```

2. 在浏览器中打开 `http://localhost:8000`

3. 在翻译器选择下拉菜单中选择"内网翻译器"

4. 选择合适的模型

5. 开始翻译

### 2. 程序接口使用

```python
from services.translator import TranslationService

# 初始化翻译服务
translator_service = TranslationService()

# 切换到内网翻译器
translator_service.set_translator_type("intranet")

# 设置模型（可选）
translator_service.set_model("deepseek-r1-32b")

# 进行翻译
result = translator_service.translate_text(
    text="你好，世界！",
    source_lang="zh",
    target_lang="en"
)
print(result)  # 输出: Hello, world!
```

## 状态检查

### 按需检测机制
内网翻译器采用按需检测机制，具有以下特点：

1. **启动时不检测**: 系统启动时不会检测内网服务状态，避免影响启动速度
2. **选择时检测**: 仅在用户选择内网翻译器时才进行连接检测
3. **实时状态**: 提供专门的API接口检查当前状态

### 连接状态检查
系统提供多种方式检查内网服务的连接状态：

```python
# 检查内网服务是否可用
is_available = translator_service.check_intranet_service()
print(f"内网服务状态: {'可用' if is_available else '不可用'}")
```

### Web API状态检查
```bash
# 通过API检查内网翻译器状态
curl http://localhost:8000/api/intranet/status
```

### 服务器启动日志
启动Web服务器时，会显示内网翻译器的配置状态：
```
内网翻译器已配置，将在用户选择时进行连接检测
```

## 故障排除

### 常见问题

1. **连接超时**
   - 检查内网地址是否正确
   - 确认内网服务是否正常运行
   - 适当增加timeout值

2. **模型不存在**
   - 确认内网部署的模型名称
   - 在配置中使用正确的模型名称

3. **API格式错误**
   - 确保内网API兼容OpenAI Chat Completions格式
   - 检查API地址是否包含正确的路径

### 调试方法

1. **查看日志**
   ```bash
   # 启动时会显示详细的连接测试信息
   python web_server.py
   ```

2. **运行测试脚本**
   ```bash
   python test_intranet_translator.py
   ```

3. **手动测试API**
   ```bash
   curl -X POST "http://192.168.100.71:8000/v1/chat/completions" \
       -H "Content-Type: application/json" \
       -d '{
           "model": "deepseek-r1-70b",
           "messages": [{"role": "user", "content": "测试连接"}],
           "stream": false
       }'
   ```

## 安全注意事项

1. **网络安全**: 确保内网API服务的安全性
2. **访问控制**: 建议配置适当的访问控制策略
3. **数据隐私**: 内网翻译可以保护数据不离开内网环境

## 更新历史

- **v1.0** (2025-01-26): 初始版本，支持基本的内网翻译功能
  - 添加IntranetTranslator类
  - 集成到TranslationService
  - Web界面支持
  - 配置文件支持
